{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here comes the next fitting technique. Wooo!!!!! So, principal component analysis (PCA) seems like it will be the most promising fitting method, as evidenced in the paper (de Oliveira-Costa et al. 2008). It is an efficient way to compress data as we are able to fit the data with as few parameters as possible while maintaining accuracy. When there are too many parameters, it leads to the risk of overfitting. \n",
    "\n",
    "Summary of steps for PCA:\n",
    "<ol>\n",
    "<li>Standardize the data (to ensure the data is at the same scale)</li>\n",
    "<li>Find the covariance matrix </li>\n",
    "<li>Compute eigenvalues and eigenvectors </li>\n",
    "<li>Rank eigenvectors </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "%matplotlib notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.load('500pixels.npz')\n",
    "data_matrix = data['arr_0'] #matrix of intensity 500x30\n",
    "x_freq = [0.01, 0.022, 0.045, 0.408, 1.42,2.326]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_data = np.load('overlapping_pixels.npz')\n",
    "overlap_matrix = overlap_data['arr_0']\n",
    "overlap_x = np.arange(overlap_matrix.shape[1])\n",
    "overlap_dict = dict(zip(x_freq,\n",
    "                        (overlap_matrix[:,i] for i in range(overlap_matrix.shape[0]))\n",
    "                       ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# plt.figure()\n",
    "# plt.plot(list(overlap_dict.keys()),list(overlap_dict.values()))\n",
    "# plt.yscale('log')\n",
    "# plt.savefig('graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# plt.figure()\n",
    "# for i in range(overlap_matrix.shape[0]):\n",
    "#     plt.plot(x_freq,overlap_matrix[i])\n",
    "#     plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization and Finding Covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we need to calculate the covariance matrix. The covariance matrix should be the same dimensions as the dimensions for data which, in this case, is 2 dimensions. There are different ways to calculate the covariance matrix but essentially it requires normalizing the data set by subtracting off the mean. The steps used here to calculate the covariance matrix is as follows:\n",
    "<br>\n",
    "###  Standardize data set\n",
    "To standardize it, I just subtracted the mean value from the data set to make sure the data is the same scale. \n",
    "    Let $X$ be the matrix of the data of $nxp$ dimensions such that $X = \\begin{bmatrix}\n",
    "            x_{11} & \\ldots & x_{1p} \\\\\n",
    "            \\vdots &  & \\vdots \\\\\n",
    "            x_{n1} & \\ldots & x_{np}\\\\\n",
    "            \\end{bmatrix} $\n",
    "    <ol>\n",
    "      <li>Found the mean of each column of the matrix then put it in a vector. Let j = 1,..,p. \n",
    "                 $$u_{j} = \\frac{1}{n} \\sum_{i=1}^{n}{X_{ij}} \\quad where \\quad \\bar{u} = \\begin{bmatrix}\n",
    "                                                                                u_{1} \\\\\n",
    "                                                                                \\vdots \\\\\n",
    "                                                                                u_{p} \\\\\n",
    "                                                                                \\end{bmatrix}$$</li>\n",
    "            <li>Multiplied a vector of ones (h vector of $nx1$ size) and the transpose mean vector ($1xp$) to create a $nxp$ matrix of the mean values.</li>\n",
    "                 $$\\bar{h}\\bar{u}^{T}$$\n",
    "            <li>Subtracted mean matrix ($nxp$) from the $nxp$ matrix of data set to form B matrix ($nxp$).</li>\n",
    "                  $$B = X - \\bar{h}\\bar{u}^{T}$$\n",
    "</ol>\n",
    "\n",
    "### Find the covariance matrix\n",
    " With the standardized matrix found (B matrix), the covariance matrix of $pxp$ size can be calculated with\n",
    "    $$C = \\frac{1}{n-1} B^{T}B$$\n",
    "\n",
    "Credit: I based this off the wiki page for PCA (https://en.wikipedia.org/wiki/Principal_component_analysis#Derivation_of_PCA_using_the_covariance_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args matrix of data\n",
    "#returns covariance of data and normalized data set\n",
    "def cov_matrix(x_matrix):\n",
    "    column_vec = data_matrix[:,np.arange(x_matrix.shape[1])] #taking each column vector of matrix\n",
    "    mean_vector = np.c_[np.mean(column_vec,axis=0)] #calculating mean for each column and adding to vector\n",
    "    ones_vector = np.ones([x_matrix.shape[0],1]) #one vector \n",
    "#     print('Mean value ', np.dot(ones_vector,mean_vector.T), 'and mean vector \\n', mean_vector)\n",
    "    b_matrix = x_matrix - np.dot(ones_vector,mean_vector.T) #subtracting mean value \n",
    "    cov = (np.dot(b_matrix.T,b_matrix))/(x_matrix.shape[0]-1) #covariance matrix formula\n",
    "    return cov,b_matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation matrix is defined by:\n",
    "$$R_{jk} = \\frac{C_{jk}}{\\sigma_{j} \\sigma_{k}}$$\n",
    "so that $-1 \\leq R_{jk} \\leq 1$ and $R_{jj} = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arg covariance matrix\n",
    "#returns correlation matrix\n",
    "def corr_matrix(c):\n",
    "    sigma = np.sqrt(np.diag(c)) #sigma vector\n",
    "    c = c/ sigma[:,None] #divide columns of c_matrix by sigma vector\n",
    "    c = c /sigma[None,:] #divide rows of c_matrix by sigma vector\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvalues and Eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the covariance matrix, we can find eigenvectors $\\bar{v}$ such that $C\\bar{v}=\\lambda \\bar{v}$ for eigenvalue $\\lambda$. For a $pxp$ covariance matrix there will be $p$ eigenvectors with a corresponding set of eigenvalues. To determine how much information or variance is attributed to each principal component, you can calculate the explained variance. You determine the sum of all the eigenvalues and divide each eigenvalue by that sum. The result is a percentage of the total variance that is explained by each eigenvalue.\n",
    "\n",
    "With the explained variance, we can rank the eigenvectors by the eigenvalue with their corresponding eigenvectors from highest to lowest to determine an order of significane. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cov,stand_matrix = cov_matrix(data_matrix)\n",
    "eigval,eigvec = np.linalg.eig(cov) #finding eigenvalues and eigenvectors\n",
    "eig_pairs = [(eigval[i],eigvec[:,i]) for i in range(eigvec.shape[1])] #creating a tuple of eigval and eigvec\n",
    "eig_pairs.sort() #sorting from least to greatest\n",
    "eig_pairs.reverse() #reversing order to greatest to least"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.93313361 0.79396109 0.63581881 0.47671384 0.3297681\n",
      "  0.21420729 0.13423696 0.08320594 0.05396284 0.04089196 0.03948756\n",
      "  0.04578675 0.05612499 0.06751609 0.07804537 0.08683972 0.09374747\n",
      "  0.0989856  0.10289164 0.1057936  0.10796059 0.10959726 0.11085202\n",
      "  0.11183229 0.11261293 0.11324835 0.11377511 0.1142191  0.11459861]\n",
      " [0.93313361 1.         0.95859595 0.86483702 0.73914889 0.59709175\n",
      "  0.46640831 0.3625747  0.28671424 0.23441836 0.20014981 0.17901161\n",
      "  0.16701153 0.16086546 0.15799592 0.15663536 0.15576985 0.15493648\n",
      "  0.1539954  0.15295479 0.15187065 0.1507956  0.14976549 0.14879759\n",
      "  0.14789856 0.14706614 0.14629716 0.14558507 0.14492394 0.14430843]\n",
      " [0.79396109 0.95859595 1.         0.97038113 0.88957271 0.77158907\n",
      "  0.64684863 0.53803725 0.45257118 0.3890368  0.34279906 0.309294\n",
      "  0.28498086 0.26723826 0.25408251 0.24404431 0.23610709 0.22962047\n",
      "  0.22419205 0.21958484 0.21564826 0.21226982 0.20935691 0.20682784\n",
      "  0.2046138  0.20265544 0.20090726 0.19933155 0.19789961 0.1965894 ]\n",
      " [0.63581881 0.86483702 0.97038113 1.         0.97150057 0.89301404\n",
      "  0.79179163 0.69392635 0.61165323 0.54668258 0.49598177 0.45597933\n",
      "  0.42406588 0.39858306 0.37831859 0.36221682 0.34934857 0.33895566\n",
      "  0.33046425 0.32345385 0.31761812 0.3127215  0.30857724 0.30503291\n",
      "  0.30196689 0.29928095 0.29690121 0.29476952 0.29284242 0.29108705]\n",
      " [0.47671384 0.73914889 0.88957271 0.97150057 1.         0.97333664\n",
      "  0.91019955 0.83661318 0.76819582 0.70979253 0.66057023 0.61856754\n",
      "  0.58259159 0.55226376 0.52731738 0.50719881 0.49111793 0.47825059\n",
      "  0.46788208 0.45944771 0.45252074 0.44677399 0.44195366 0.43785974\n",
      "  0.43433693 0.43126376 0.42855001 0.42612652 0.42394196 0.42195772]\n",
      " [0.3297681  0.59709175 0.77158907 0.89301404 0.97333664 1.\n",
      "  0.98054909 0.93819669 0.89031913 0.84438051 0.80176344 0.76223039\n",
      "  0.72606944 0.69419329 0.66729477 0.64537027 0.62784446 0.61391109\n",
      "  0.60279122 0.5938391  0.58655659 0.58056295 0.57556683 0.5713438\n",
      "  0.56772291 0.56457334 0.56179898 0.55932745 0.55710533 0.55509247]\n",
      " [0.21420729 0.46640831 0.64684863 0.79179163 0.91019955 0.98054909\n",
      "  1.         0.9876664  0.9612467  0.92995132 0.89688327 0.86316501\n",
      "  0.83021326 0.79991297 0.77371681 0.75211622 0.73479758 0.72106253\n",
      "  0.71016004 0.70143998 0.69439098 0.68862117 0.68383251 0.67979848\n",
      "  0.67634861 0.6733544  0.67072221 0.66838234 0.66628355 0.66438726]\n",
      " [0.13423696 0.3625747  0.53803725 0.69392635 0.83661318 0.93819669\n",
      "  0.9876664  1.         0.99237044 0.97495627 0.95199171 0.92548482\n",
      "  0.89754997 0.87067387 0.84682351 0.82688192 0.81079667 0.7980265\n",
      "  0.78790885 0.77984286 0.77334544 0.76804388 0.7636549  0.75996475\n",
      "  0.75681377 0.75408282 0.75168551 0.74955812 0.74765382 0.74593729]\n",
      " [0.08320594 0.28671424 0.45257118 0.61165323 0.76819582 0.89031913\n",
      "  0.9612467  0.99237044 1.         0.99474178 0.98143697 0.96252384\n",
      "  0.94041395 0.91787531 0.89718951 0.87954992 0.86516309 0.85367783\n",
      "  0.84455961 0.8372903  0.83144002 0.82667215 0.82272928 0.81941737\n",
      "  0.81659184 0.81414535 0.81200026 0.81009955 0.80840134 0.80687388]\n",
      " [0.05396284 0.23441836 0.3890368  0.54668258 0.70979253 0.84438051\n",
      "  0.92995132 0.97495627 0.99474178 1.         0.99577765 0.98456969\n",
      "  0.96875233 0.95111227 0.93408701 0.91911954 0.90667713 0.89662631\n",
      "  0.88859138 0.88216167 0.87697779 0.87275012 0.86925364 0.86631749\n",
      "  0.86381385 0.86164783 0.85975065 0.85807188 0.85657441 0.85523004]\n",
      " [0.04089196 0.20014981 0.34279906 0.49598177 0.66057023 0.80176344\n",
      "  0.89688327 0.95199171 0.98143697 0.99577765 1.         0.99640341\n",
      "  0.987097   0.97469253 0.96165565 0.94961999 0.93930295 0.93080154\n",
      "  0.92391759 0.91836444 0.91386541 0.91018589 0.90713817 0.90457726\n",
      "  0.90239351 0.90050501 0.89885207 0.89739085 0.89608896 0.89492175]\n",
      " [0.03948756 0.17901161 0.309294   0.45597933 0.61856754 0.76223039\n",
      "  0.86316501 0.92548482 0.96252384 0.98456969 0.99640341 1.\n",
      "  0.99707792 0.98995387 0.98102321 0.97204703 0.9639629  0.95709019\n",
      "  0.95141086 0.94676834 0.94297465 0.9398549  0.93726195 0.93507869\n",
      "  0.93321488 0.9316023  0.93019077 0.92894323 0.92783219 0.92683667]\n",
      " [0.04578675 0.16701153 0.28498086 0.42406588 0.58259159 0.72606944\n",
      "  0.83021326 0.89754997 0.94041395 0.96875233 0.987097   0.99707792\n",
      "  1.         0.99783902 0.99285543 0.98687456 0.98100678 0.97576494\n",
      "  0.97129654 0.96756915 0.96448199 0.96192009 0.95977753 0.95796578\n",
      "  0.95641454 0.95506967 0.95389081 0.95284788 0.95191843 0.95108528]\n",
      " [0.05612499 0.16086546 0.26723826 0.39858306 0.55226376 0.69419329\n",
      "  0.79991297 0.87067387 0.91787531 0.95111227 0.97469253 0.98995387\n",
      "  0.99783902 1.         0.99853479 0.99528002 0.99146461 0.98775264\n",
      "  0.98442945 0.9815707  0.9791541  0.97712006 0.97540154 0.97393736\n",
      "  0.97267652 0.97157861 0.97061293 0.96975631 0.96899132 0.96830447]\n",
      " [0.06751609 0.15799592 0.25408251 0.37831859 0.52731738 0.66729477\n",
      "  0.77371681 0.84682351 0.89718951 0.93408701 0.96165565 0.98102321\n",
      "  0.99285543 0.99853479 1.         0.99906418 0.99702652 0.99465864\n",
      "  0.99235144 0.99026751 0.98845004 0.98688698 0.98554545 0.98438864\n",
      "  0.98338305 0.98250082 0.9817202  0.98102444 0.98040077 0.97983917]\n",
      " [0.07804537 0.15663536 0.24404431 0.36221682 0.50719881 0.64537027\n",
      "  0.75211622 0.82688192 0.87954992 0.91911954 0.94961999 0.97204703\n",
      "  0.98687456 0.99528002 0.99906418 1.         0.99942208 0.99817313\n",
      "  0.99672017 0.99529177 0.99398269 0.99281941 0.99179727 0.99089999\n",
      "  0.99010897 0.98940718 0.98878064 0.98821825 0.98771133 0.9872529 ]\n",
      " [0.08683972 0.15576985 0.23610709 0.34934857 0.49111793 0.62784446\n",
      "  0.73479758 0.81079667 0.86516309 0.90667713 0.93930295 0.9639629\n",
      "  0.98100678 0.99146461 0.99702652 0.99942208 1.         0.99964814\n",
      "  0.99888658 0.99799231 0.9970992  0.99626372 0.99550356 0.99481895\n",
      "  0.99420341 0.9936488  0.99314759 0.9926934  0.99228096 0.99190586]\n",
      " [0.09374747 0.15493648 0.22962047 0.33895566 0.47825059 0.61391109\n",
      "  0.72106253 0.7980265  0.85367783 0.89662631 0.93080154 0.95709019\n",
      "  0.97576494 0.98775264 0.99465864 0.99817313 0.99964814 1.\n",
      "  0.99978559 0.99931695 0.99875713 0.99818534 0.99763653 0.99712379\n",
      "  0.99665017 0.99621459 0.99581468 0.99544784 0.9951116  0.99480363]\n",
      " [0.0989856  0.1539954  0.22419205 0.33046425 0.46788208 0.60279122\n",
      "  0.71016004 0.78790885 0.84455961 0.88859138 0.92391759 0.95141086\n",
      "  0.97129654 0.98442945 0.99235144 0.99672017 0.99888658 0.99978559\n",
      "  1.         0.99986737 0.99957238 0.99921137 0.99883237 0.99845833\n",
      "  0.99809962 0.99776065 0.99744307 0.99714727 0.99687301 0.99661958]\n",
      " [0.10289164 0.15295479 0.21958484 0.32345385 0.45944771 0.5938391\n",
      "  0.70143998 0.77984286 0.8372903  0.88216167 0.91836444 0.94676834\n",
      "  0.96756915 0.9815707  0.99026751 0.99529177 0.99799231 0.99931695\n",
      "  0.99986737 1.         0.99991566 0.99972356 0.99948163 0.99922024\n",
      "  0.9989554  0.99869568 0.99844584 0.9982086  0.99798545 0.99777702]\n",
      " [0.1057936  0.15187065 0.21564826 0.31761812 0.45252074 0.58655659\n",
      "  0.69439098 0.77334544 0.83144002 0.87697779 0.91386541 0.94297465\n",
      "  0.96448199 0.9791541  0.98845004 0.99398269 0.9970992  0.99875713\n",
      "  0.99957238 0.99991566 1.         0.99994432 0.99981403 0.99964515\n",
      "  0.9994579  0.99926404 0.99907073 0.99888249 0.99870215 0.9985314 ]\n",
      " [0.10796059 0.1507956  0.21226982 0.3127215  0.44677399 0.58056295\n",
      "  0.68862117 0.76804388 0.82667215 0.87275012 0.91018589 0.9398549\n",
      "  0.96192009 0.97712006 0.98688698 0.99281941 0.99626372 0.99818534\n",
      "  0.99921137 0.99972356 0.99994432 1.         0.99996167 0.99986964\n",
      "  0.99974733 0.99960894 0.99946344 0.99931674 0.99917276 0.99903402]\n",
      " [0.10959726 0.14976549 0.20935691 0.30857724 0.44195366 0.57556683\n",
      "  0.68383251 0.7636549  0.82272928 0.86925364 0.90713817 0.93726195\n",
      "  0.95977753 0.97540154 0.98554545 0.99179727 0.99550356 0.99763653\n",
      "  0.99883237 0.99948163 0.99981403 0.99996167 1.         0.99997256\n",
      "  0.99990526 0.99981411 0.99970952 0.99959848 0.99948574 0.9993745 ]\n",
      " [0.11085202 0.14879759 0.20682784 0.30503291 0.43785974 0.5713438\n",
      "  0.67979848 0.75996475 0.81941737 0.86631749 0.90457726 0.93507869\n",
      "  0.95796578 0.97393736 0.98438864 0.99089999 0.99481895 0.99712379\n",
      "  0.99845833 0.99922024 0.99964515 0.99986964 0.99997256 1.\n",
      "  0.99997972 0.99992921 0.99985993 0.99977974 0.99969408 0.99960669]\n",
      " [0.11183229 0.14789856 0.2046138  0.30196689 0.43433693 0.56772291\n",
      "  0.67634861 0.75681377 0.81659184 0.86381385 0.90239351 0.93321488\n",
      "  0.95641454 0.97267652 0.98338305 0.99010897 0.99420341 0.99665017\n",
      "  0.99809962 0.9989554  0.9994579  0.99974733 0.99990526 0.99997972\n",
      "  1.         0.99998467 0.9999461  0.99989279 0.99983075 0.99976418]\n",
      " [0.11261293 0.14706614 0.20265544 0.29928095 0.43126376 0.56457334\n",
      "  0.6733544  0.75408282 0.81414535 0.86164783 0.90050501 0.9316023\n",
      "  0.95506967 0.97157861 0.98250082 0.98940718 0.9936488  0.99621459\n",
      "  0.99776065 0.99869568 0.99926404 0.99960894 0.99981411 0.99992921\n",
      "  0.99998467 1.         0.99998824 0.99995847 0.99991713 0.99986882]\n",
      " [0.11324835 0.14629716 0.20090726 0.29690121 0.42855001 0.56179898\n",
      "  0.67072221 0.75168551 0.81200026 0.85975065 0.89885207 0.93019077\n",
      "  0.95389081 0.97061293 0.9817202  0.98878064 0.99314759 0.99581468\n",
      "  0.99744307 0.99844584 0.99907073 0.99946344 0.99970952 0.99985993\n",
      "  0.9999461  0.99998824 1.         0.9999909  0.99996777 0.99993552]\n",
      " [0.11377511 0.14558507 0.19933155 0.29476952 0.42612652 0.55932745\n",
      "  0.66838234 0.74955812 0.81009955 0.85807188 0.89739085 0.92894323\n",
      "  0.95284788 0.96975631 0.98102444 0.98821825 0.9926934  0.99544784\n",
      "  0.99714727 0.9982086  0.99888249 0.99931674 0.99959848 0.99977974\n",
      "  0.99989279 0.99995847 0.9999909  1.         0.99999292 0.99997484]\n",
      " [0.1142191  0.14492394 0.19789961 0.29284242 0.42394196 0.55710533\n",
      "  0.66628355 0.74765382 0.80840134 0.85657441 0.89608896 0.92783219\n",
      "  0.95191843 0.96899132 0.98040077 0.98771133 0.99228096 0.9951116\n",
      "  0.99687301 0.99798545 0.99870215 0.99917276 0.99948574 0.99969408\n",
      "  0.99983075 0.99991713 0.99996777 0.99999292 1.         0.99999445]\n",
      " [0.11459861 0.14430843 0.1965894  0.29108705 0.42195772 0.55509247\n",
      "  0.66438726 0.74593729 0.80687388 0.85523004 0.89492175 0.92683667\n",
      "  0.95108528 0.96830447 0.97983917 0.9872529  0.99190586 0.99480363\n",
      "  0.99661958 0.99777702 0.9985314  0.99903402 0.9993745  0.99960669\n",
      "  0.99976418 0.99986882 0.99993552 0.99997484 0.99999445 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "corr = corr_matrix(cov)\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_eig = np.sum(eigval)\n",
    "var_exp = np.sort([(eigval[i]/total_eig) for i in np.arange(eigval.size)]) #calculating and sorting explained variance\n",
    "var_exp = var_exp[::-1] #reverse array to descending order\n",
    "eigval_dict = dict(zip(np.arange(1,var_exp.size+1),var_exp)) #adding ordered eigvalues to dictionary with rank as key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(eigval_dict.keys(),eigval_dict.values())\n",
    "plt.plot(list(eigval_dict.keys()),list(eigval_dict.values()))\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Principal component number')\n",
    "plt.ylabel('Fraction of variance explained')\n",
    "plt.title('Rank of Eigenvalues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('Eigenvectors')\n",
    "for i in np.arange(1):\n",
    "    plt.plot(eigvec[:,i])\n",
    "#     plt.quiver([0,0],*eigvec[:,i],scale=1.15,color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Vector and Final Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the explained variance, you can leave out components that are less signficant which results in the final data having less dimensions than the original. We put the eigenvectors of importance in the <b>feature vector</b>.\n",
    "\n",
    "After forming the feature vector, we can determine the final data set which will reorient the data to be represented by the principal components instead of the original axes. You multiply the tranpose of the feature vector with the tranpose of the standardized data matrix (or B matrix).\n",
    "$$FinalData = FeatureVector^{T} * B^{T}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_vec = np.array(eig_pairs[0][1]).reshape(cov.shape[0],1) #feature vector\n",
    "# print(feature_vec)\n",
    "final_data = np.dot(feature_vec.T,stand_matrix.T) #multiplying transpose of feature vector and transpose of normalized matrix\n",
    "print(final_data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
