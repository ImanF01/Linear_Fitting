{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaring variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation data from synchroton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synch_data = pd.read_csv('Synch_spectrum.txt',sep = \"\\s+\", names = ['Frequency (Hz)','Intensity (erg cm-2 s-1 sr-1 Hz-1)'],skiprows = [0,1])\n",
    "# xpoints = synch_data['Frequency (Hz)']\n",
    "# ypoints = synch_data['Intensity (erg cm-2 s-1 sr-1 Hz-1)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averages of the intensities for the 9 different areas in the sky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class LeastSquares:\n",
    "    \n",
    "    avg_data = pd.read_csv('Data/avg_intensities.txt',sep = \"\\s+\", names = ['Frequency (GHz)','Intensity'],skiprows = [0,1])\n",
    "    xpoints = avg_data['Frequency (GHz)'].iloc[:30] #assigning x values to frequency column\n",
    "    xpoints_arr = xpoints[np.arange(xpoints.size)].values.reshape((xpoints.size,1)) #array of x values reshaped\n",
    "    begin_x = np.linspace(0.01,0.05, 10,endpoint=False).reshape(10,1) #additional x points to extend curve\n",
    "    xpoints_arr = np.vstack([begin_x,xpoints_arr]) #combining begin_x array and xpoints_arr array\n",
    "    # one_arr = np.ones([xpoints_arr.size,1]) #array of ones concatenated to matrices\n",
    "    ypoints_arr = avg_data['Intensity'].values.reshape((9,30)) #2d array of intensity values (9x30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def __init__(self):\n",
    "        self.data = data\n",
    "        \n",
    "# %store -r clean_freq\n",
    "# %store -r mean_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining x matrices and y vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I am taking the x and y points and adding them to their respective matrices. Note that the 'xmatrix' is equivalent to the A matrix in Adrian's notes. For a linear or quadratic x matrix:\n",
    "\n",
    "$$X_{linear} = \\begin{bmatrix}\n",
    "1 & x_{1} \\\\\n",
    "1 & x_{2} \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "\\end{bmatrix}, \\quad\n",
    "X_{quadratic} = \\begin{bmatrix}\n",
    "1 & x_{1} & x_{1}^{2}\\\\\n",
    "1 & x_{2} & x_{2}^{2} \\\\\n",
    "\\vdots & \\vdots & \\vdots\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "For a cubic function just add another column for $x^3$. While the y vector is just the y points:\n",
    "$\\bar{y} = \\begin{bmatrix}\n",
    "y_{1} \\\\\n",
    "y_{2} \\\\\n",
    "\\vdots \\\\\n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def poly_xmatrix(data):\n",
    "        one_arr = np.ones([data.size,1]) #array of ones concatenated to matrices\n",
    "        lin_m = np.hstack([one_arr, data]) #appending array of ones to array of xvalues data matrix for linear model\n",
    "        quad_m = np.hstack([lin_m,data**2]) #appending lin_m to array of xvalues squared \n",
    "        cub_m = np.hstack([quad_m,data**3]) #appending xmatrix_quad to array of xvalues cubed\n",
    "        return lin_m, quad_m, cub_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Law"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an attempt to fit a power law in the form of $y = \\beta x^\\alpha$. To fit the power law, it must be linearized since, according to Adrian's notes, the \"linear part of the term 'linear fit' just means linear in the parameters\". One way to do that (based on online searching) is by applying log to both sides to make:\n",
    "\n",
    "$log(y) = log (\\beta x^\\alpha) = log(\\beta) + log(x^\\alpha) = log(\\beta) + \\alpha log(x)$\n",
    "\n",
    "Therefore, the linearization of $y = \\beta x^\\alpha$ is $log(y) = log(\\beta) + \\alpha log(x)$. Let $y^{'}=log(y)$ and $x^{'}=log(x)$ so that $y^{'} = log(\\beta) + \\alpha x^{'}$.\n",
    "\n",
    "With this, we can pretty much proceed as with the linear case but here the x matrix and y vector will be:\n",
    "\n",
    "$$X_{power} = \\begin{bmatrix}\n",
    "1 & log(x_{1}) \\\\\n",
    "1 & log(x_{2}) \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "\\end{bmatrix}, \\quad\n",
    "\\bar{y} = \\begin{bmatrix}\n",
    "log(y_{1}) \\\\\n",
    "log(y_{2}) \\\\\n",
    "\\vdots \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def pow_xmatrix(data):\n",
    "        one_arr = np.ones([data.size,1])\n",
    "        pow_m = np.hstack([one_arr,np.log(data)]) #appending array of ones to array of log xvalues\n",
    "        return pow_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise covariance matrix and y model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is based on Adrian's notes to determing the $\\hat{x}$ for $y^{model} = A\\hat{x}$. From his notes, $\\hat{x}$ is defined as $\\hat{x} = [A^TN^{-1}A]^{-1}A^TN^{-1}\\bar{y}$.\n",
    "\n",
    "From the earlier code, I already found $A$ = xmatrix and $\\bar{y}$. To find $N$, I first need to find the variance or $\\sigma^{2}$. The $N$ matrix is as follows:\n",
    "$$ N = \\begin{pmatrix}\n",
    "\\sigma_{1}^{2} & 0 & 0 &\\ldots{} \\\\\n",
    "0 & \\sigma_{2}^{2} & 0 & \\ldots{} \\\\\n",
    "0 & 0 & \\sigma_{3}^{2} & \\ldots{} \\\\\n",
    "\\vdots & \\vdots & \\ddots \\\\\n",
    "\\end{pmatrix} $$\n",
    "\n",
    "To find $\\sigma^{2}$, I used the following formula where $N$ is the number of terms and $\\mu$ is the mean:\n",
    "$\\sigma^{2} = \\frac{1}{N} \\sum_{i}^{N}{(x_{i} - \\mu)^{2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I have determined the values for $A, N, \\bar{y}$, finding $\\hat{x}$ is just a matter of multiplying everything for $\\hat{x} = [A^TN^{-1}A]^{-1}A^TN^{-1}\\bar{y}$. I broke down the steps of the process:\n",
    "<ol>\n",
    "<li>$A^TN^{-1}$</li>\n",
    "<li>$A^TN^{-1}\\bar{y}$</li>\n",
    "<li>$[A^TN^{-1}A]^{-1}$</li>\n",
    "<li>$\\hat{x} = [A^TN^{-1}A]^{-1}A^TN^{-1}\\bar{y}$</li>\n",
    "<li>$y^{model} = A\\hat{x}$</li>\n",
    "</ol>\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below function, since I am adding additional x points to extend the curve, I am calculating the x-bar (parameters for fit) based on the x-values from the data. Then, after calculating x bar, I am multiplying the x_matrix which has both the x-values from the data and the additional x points to extend the curve with x_bar to get the y values for the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #parameters x_matrix, x points, y points, noise covariance, index of x matrix where begin_x values end \n",
    "    #default for noise covariance is identity matrix\n",
    "    #default for index_begin_x is index where xpoints from data start for x_matrix\n",
    "    #returns y_model, x_bar (parameters for fit) and error covariance\n",
    "\n",
    "    def y_model(x_matrix,yval,noise_cov=None):\n",
    "        if noise_cov == None:\n",
    "            noise_cov = np.identity(x_matrix.shape[0])\n",
    "\n",
    "    #     calculating x_bar with sliced x_matrix\n",
    "        dot_matrix = np.dot(x_matrix.T,np.linalg.inv(noise_cov)) #Step 1\n",
    "        doty_matrix = np.dot(dot_matrix,yval) #Step 2\n",
    "        inv_matrix = np.linalg.inv(np.dot(dot_matrix,x_matrix)) #Step 3\n",
    "        x_bar = np.dot(inv_matrix, doty_matrix) #Step 4\n",
    "\n",
    "        #calculating y_model with x_matrix which has both x values from data and additional x points\n",
    "        predict_y = np.dot(x_matrix, x_bar) #Step 5\n",
    "        return predict_y, x_bar, inv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def y_model_extend(x_matrix_extend,yval,index_begin_x):\n",
    "        data_matrix = x_matrix_extend[index_begin_x:] #slicing array to section with only x values from data\n",
    "        predict_y,x_bar,inv_matrix = y_model(data_matrix,yval)\n",
    "        predict_y = np.dot(x_matrix_extend, x_bar)\n",
    "        return predict_y,x_bar,inv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     #variance = np.hstack(yerr**2) #stack array horizontally  \n",
    "#     avg_x = np.mean(xval) #average of x points\n",
    "#     variance = avg_x\n",
    "#     noise_cov = variance * np.identity(xpoints.size)\n",
    "#     avg_y = np.mean(yval) #average of x points\n",
    "#     variance =(((yval - avg_y)**2)/(yval.size)).values.reshape((yval.size,1)) #calculating variance\n",
    "#     variance = np.hstack(variance)\n",
    "#     noise_cov = np.diag(variance) #diagonal of variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to find error information on final parameters to ascertain how far the fit is to the true parameters. To determine it, use the error covariance defined as $V= [A^{T}N^{-1}A]^{-1}$. The square root of the diagonal of $V$ gives the error bar of each parameter. The off-diagonal elements tell us how the errors on different parameters are correlated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def error_bar(x_matrix):\n",
    "        return np.sqrt(np.diag(x_matrix)) #taking the square root of the diagonal of V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling Functions and Graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xpoints_arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-dcf330edbb29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxmatrix_quad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxmatrix_cub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoly_xmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxpoints_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mxmatrix_pow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpow_xmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxpoints_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xpoints_arr' is not defined"
     ]
    }
   ],
   "source": [
    "xmatrix, xmatrix_quad, xmatrix_cub = poly_xmatrix(xpoints_arr)\n",
    "xmatrix_pow = pow_xmatrix(xpoints_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_freq_arr = (np.array(x_freq)).reshape(len(x_freq),1)\n",
    "mean_pow = pow_xmatrix(x_freq_arr)\n",
    "log_mean_y = (np.log(mean_y)).reshape(mean_y.shape[0],1)\n",
    "\n",
    "pow_freq_fit, pow_freq_param, pow_error2 = y_model(mean_pow, log_mean_y) \n",
    "%store pow_freq_fit\n",
    "%store pow_freq_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rd = np.random.default_rng()\n",
    "#yerr= rd.random((ypoints.size))*10**10\n",
    "#plt.errorbar(xpoints,ypoints,yerr,fmt='r.') \n",
    "#plt.scatter(avg_data['Frequency (GHz)'],avg_data['Intensity'], color='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in np.arange(ypoints_arr.shape[0]): #looping through 9 rows of ypoints_arr\n",
    "    plt.figure()\n",
    "    \n",
    "    lin_fit, lin_param, lin_error = y_model_extend(xmatrix,ypoints_arr[i],10)\n",
    "    quad_fit, quad_param, quad_error = y_model_extend(xmatrix_quad,ypoints_arr[i],10)\n",
    "    cub_fit, cub_param, cub_error = y_model_extend(xmatrix_cub,ypoints_arr[i],10)\n",
    "    \n",
    "    plt.plot(xpoints_arr, lin_fit, label='linear')\n",
    "    plt.plot(xpoints_arr, quad_fit, label='quadratic')\n",
    "    plt.plot(xpoints_arr, cub_fit, label='cubic')\n",
    "    plt.scatter(xpoints,ypoints_arr[i], color='m')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title(\"Linear Best Fit\")\n",
    "    plt.xlabel(xpoints.name)\n",
    "    plt.ylabel('Intensity')\n",
    "    plt.xlim(left=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xval_log= np.log(xpoints_arr) #finding log of extended x points \n",
    "\n",
    "for j in np.arange(ypoints_arr.shape[0]):\n",
    "    plt.figure()\n",
    "    yval_log = np.log(ypoints_arr[i]) #log of y points\n",
    "    pow_fit, pow_param, pow_error = y_model_extend(xmatrix_pow,yval_log,10)\n",
    "    plt.plot(xval_log, pow_fit, label='power')\n",
    "    plt.scatter(np.log(xpoints),yval_log, color='m')\n",
    "    plt.title(\"Linear Best Fit for Power (log-log)\")\n",
    "    plt.xlabel(xpoints.name)\n",
    "    plt.ylabel('Intensity')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Errors for Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the error for parameters of the linear fit. The parameters are $b$ for intercept and $m$ for slope from the equation $y=mx+b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error_cov_lin = error_bar(lin_error)\n",
    "print('Error covariance for linear fit is\\n', error_cov_lin)\n",
    "print('\\nThe slope (m) is', lin_param[1],'+/-', error_cov_lin[1], '(',lin_param[1]+error_cov_lin[1],',',\n",
    "      lin_param[1]-error_cov_lin[1],')')\n",
    "print('The intercept (b) is', lin_param[0],'+/-', error_cov_lin[0],'(',lin_param[0]+error_cov_lin[0],',',\n",
    "      lin_param[0]-error_cov_lin[0],')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the error for the parameter of the power law fit. The parameters are $log(\\beta)$ and $\\alpha$ for the equation $y^{'} = log(\\beta) + \\alpha x^{'}$. Note that $y^{'}=log(y)$ and $x^{'}=log(x)$ and that it's for a log-log graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Error covariance for power law fit is \\n', error_cov(xmatrix_pow))\n",
    "# print('\\nLog(beta) is', pow_param[1],'+/-', error_bar(xmatrix_pow)[1], '(',pow_param[1]+error_bar(xmatrix_pow)[1],',',\n",
    "#       pow_param[1]-error_bar(xmatrix_pow)[1],')')\n",
    "# print('Alpha is', pow_param[0],'+/-', error_bar(xmatrix_pow)[0],'(',pow_param[0]+error_bar(xmatrix_pow)[0],',',\n",
    "#       pow_param[0]-error_bar(xmatrix_pow)[0],')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating sigma using a different method and finding the corresponding error for the power law parameters. Here, it seems that the error has been substantially reduced. The error for log is $$\\delta y^{'}= \\frac{d log(y)}{dy} = \\frac{\\delta y}{y}$$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigma = (1/(np.sqrt(np.abs(yval_log)))).reshape((ypoints.size,1))\n",
    "# sigma= np.hstack(sigma)\n",
    "# noise_cov = np.diag(sigma)\n",
    "# err_pow = error_cov(xmatrix_pow)\n",
    "# print(err_pow)\n",
    "# print('\\nLog(beta) is', pow_param[1],'+/-', error_bar(xmatrix_pow)[1], '(',pow_param[1]+error_bar(xmatrix_pow)[1],',',\n",
    "#       pow_param[1]-error_bar(xmatrix_pow)[1],')')\n",
    "# print('Alpha is', pow_param[0],'+/-', error_bar(xmatrix_pow)[0],'(',pow_param[0]+error_bar(xmatrix_pow)[0],',',\n",
    "#       pow_param[0]-error_bar(xmatrix_pow)[0],')')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
