{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Least Square Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaring variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation data from synchroton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "synch_data = pd.read_csv('Synch_spectrum.txt',sep = \"\\s+\", names = ['Frequency (Hz)','Intensity (erg cm-2 s-1 sr-1 Hz-1)'],skiprows = [0,1])\n",
    "# xpoints = synch_data['Frequency (Hz)']\n",
    "# ypoints = synch_data['Intensity (erg cm-2 s-1 sr-1 Hz-1)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averages of the intensities for the 9 different areas in the sky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_data = pd.read_csv('avg_intensities.txt',sep = \"\\s+\", names = ['Frequency (GHz)','Intensity'],skiprows = [0,1])\n",
    "xpoints = avg_data['Frequency (GHz)'].iloc[:30] \n",
    "ypoints_dict = {}\n",
    "for y in np.arange(9):\n",
    "    ypoints_dict['ypoints'+str(y)] = avg_data['Intensity'].iloc[y*30:30*(y+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#points for cubic fit\n",
    "# xpoints = np.array([-3,-2,-1,0,1,1.5,2,2.5, 3]) \n",
    "# ypoints = np.array([-24,-5,2,-5,4,7,15,20,30])\n",
    "\n",
    "# xmatrix= [] #linear\n",
    "# xmatrix_quad = [] #quadratic\n",
    "# xmatrix_cub = [] #cubic\n",
    "# xmatrix_pow = [] #power function\n",
    "# yval_log = [] #y vector for power\n",
    "\n",
    "\n",
    "# ypoints = ypoints_dict['ypoints0']\n",
    "one_arr = np.ones([xpoints.size,1]) #array of ones which is concatenated to matrices\n",
    "arr = xpoints[np.arange(xpoints.size)].values.reshape((xpoints.size,1)) #array of x values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining x matrices and y vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I am taking the x and y points and adding them to their respective matrices. Note that the 'xmatrix' is equivalent to the A matrix in Adrian's notes. For a linear or quadratic x matrix:\n",
    "\n",
    "$$X_{linear} = \\begin{bmatrix}\n",
    "1 & x_{1} \\\\\n",
    "1 & x_{2} \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "\\end{bmatrix}, \\quad\n",
    "X_{quadratic} = \\begin{bmatrix}\n",
    "1 & x_{1} & x_{1}^{2}\\\\\n",
    "1 & x_{2} & x_{2}^{2} \\\\\n",
    "\\vdots & \\vdots & \\vdots\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "For a cubic function just add another column for $x^3$. While the y vector is just the y points:\n",
    "$\\bar{y} = \\begin{bmatrix}\n",
    "y_{1} \\\\\n",
    "y_{2} \\\\\n",
    "\\vdots \\\\\n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmatrix = np.hstack([one_arr, arr]) #appending array of ones to array of xvalues\n",
    "xmatrix_quad = np.hstack([xmatrix,arr**2]) #appending xmatrix to array of xvalues squared \n",
    "xmatrix_cub = np.hstack([xmatrix_quad,arr**3]) #appending xmatrix_quad to array of xvalues cubed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Law"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an attempt to fit a power law in the form of $y = \\beta x^\\alpha$. To fit the power law, it must be linearized since, according to Adrian's notes, the \"linear part of the term 'linear fit' just means linear in the parameters\". One way to do that (based on online searching) is by applying log to both sides to make:\n",
    "\n",
    "$log(y) = log (\\beta x^\\alpha) = log(\\beta) + log(x^\\alpha) = log(\\beta) + \\alpha log(x)$\n",
    "\n",
    "Therefore, the linearization of $y = \\beta x^\\alpha$ is $log(y) = log(\\beta) + \\alpha log(x)$. Let $y^{'}=log(y)$ and $x^{'}=log(x)$ so that $y^{'} = log(\\beta) + \\alpha x^{'}$.\n",
    "\n",
    "With this, we can pretty much proceed as with the linear case but here the x matrix and y vector will be:\n",
    "\n",
    "$$X_{power} = \\begin{bmatrix}\n",
    "1 & log(x_{1}) \\\\\n",
    "1 & log(x_{2}) \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "\\end{bmatrix}, \\quad\n",
    "\\bar{y} = \\begin{bmatrix}\n",
    "log(y_{1}) \\\\\n",
    "log(y_{2}) \\\\\n",
    "\\vdots \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ypoints' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e823d3c706c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mxmatrix_pow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mone_arr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#appending array of ones to array of log xvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0myval_log\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mypoints\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#array of log yvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ypoints' is not defined"
     ]
    }
   ],
   "source": [
    "xmatrix_pow = np.hstack([one_arr,np.log(arr)]) #appending array of ones to array of log xvalues\n",
    "# yval_log =np.log(ypoints) #array of log yvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise covariance matrix and y model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is based on Adrian's notes to determing the $\\hat{x}$ for $y^{model} = A\\hat{x}$. From his notes, $\\hat{x}$ is defined as $\\hat{x} = [A^TN^{-1}A]^{-1}A^TN^{-1}\\bar{y}$.\n",
    "\n",
    "From the earlier code, I already found $A$ = xmatrix and $\\bar{y}$. To find $N$, I first need to find the variance or $\\sigma^{2}$. The $N$ matrix is as follows:\n",
    "$$ N = \\begin{pmatrix}\n",
    "\\sigma_{1}^{2} & 0 & 0 &\\ldots{} \\\\\n",
    "0 & \\sigma_{2}^{2} & 0 & \\ldots{} \\\\\n",
    "0 & 0 & \\sigma_{3}^{2} & \\ldots{} \\\\\n",
    "\\vdots & \\vdots & \\ddots \\\\\n",
    "\\end{pmatrix} $$\n",
    "To find $\\sigma^{2}$, I used the following formula:\n",
    "$$\\sigma^{2} = \\frac{1}{N} \\sum_{i}^{N}{(x_{i} - \\mu)^{2}}$$\n",
    "where $N$ is the number of terms and $\\mu$ is the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I have determined the values ($A, N, \\bar{y}$) to find $\\hat{x}$, it's just a matter of multiplying everything for $\\hat{x} = [A^TN^{-1}A]^{-1}A^TN^{-1}\\bar{y}$. I broke down the steps of the process:\n",
    "<ol>\n",
    "<li>$A^TN^{-1}$</li>\n",
    "<li>$A^TN^{-1}\\bar{y}$</li>\n",
    "<li>$[A^TN^{-1}A]^{-1}$</li>\n",
    "<li>$\\hat{x} = [A^TN^{-1}A]^{-1}A^TN^{-1}\\bar{y}$</li>\n",
    "<li>$y^{model} = A\\hat{x}$</li>\n",
    "</ol>\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns y_model and x_bar (parameters)\n",
    "def y_model(x_matrix,xval,yval):\n",
    "    avg_x = np.mean(xval) #average of x points\n",
    "    variance =(((yval - avg_x)**2)/(xval.size)).values.reshape((yval.size,1)) \n",
    "    #variance = np.hstack(yerr**2) #stack array horizontally\n",
    "    variance = np.hstack(variance)\n",
    "    noise_cov = np.diag(variance) \n",
    "#     print(variance)\n",
    "    \n",
    "    dot_matrix = np.dot(x_matrix.T,np.linalg.inv(noise_cov)) #Step 1\n",
    "    doty_matrix = np.dot(dot_matrix,yval) #Step 2\n",
    "    inv_matrix = np.linalg.inv(np.dot(dot_matrix,x_matrix)) #Step 3\n",
    "    x_bar = np.dot(inv_matrix, doty_matrix) #Step 4\n",
    "    y_model = np.dot(x_matrix, x_bar) #Step 5\n",
    "    return y_model, x_bar, inv_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to find error information on final parameters to ascertain how far the fit is to the true parameters. To determine it, use the error covariance defined as $V= [A^{T}N^{-1}A]^{-1}$. The square root of the diagonal of $V$ gives the error bar of each parameter. The off-diagonal elements tell us how the errors on different parameters are correlated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def error_cov(x_matrix):\n",
    "#     dot_matrix = np.dot(x_matrix.T,np.linalg.inv(noise_cov)) #Step 1 from Noise covariance matrix section\n",
    "#     error = np.linalg.inv(np.dot(dot_matrix,x_matrix)) #Step 3 from Noise covariance matrix section\n",
    "#     return error\n",
    "\n",
    "def error_bar(x_matrix):\n",
    "    return np.sqrt(np.diag(x_matrix)) #taking the square root of the diagonal of V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling Functions and Graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xval_log= np.log(xpoints)\n",
    "\n",
    "lin_fit, lin_param, lin_error = y_model(xmatrix, xpoints, ypoints)\n",
    "quad_fit, quad_param, quad_error = y_model(xmatrix_quad, xpoints,ypoints)\n",
    "cub_fit, cub_param, cub_error = y_model(xmatrix_cub,xpoints, ypoints)\n",
    "pow_fit, pow_param, pow_error = y_model(xmatrix_pow, xval_log, yval_log)\n",
    "\n",
    "x_extended = np.linspace(0,0.05,10)\n",
    "y_extended = lin_param[1]*x_extended + lin_param[0]\n",
    "rd = np.random.default_rng()\n",
    "yerr= rd.random((ypoints.size))*10**10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #plot for first figure\n",
    "# plt.figure(1)\n",
    "# # plt.errorbar(xpoints,ypoints,yerr,fmt='r.') \n",
    "# plt.plot(xpoints, lin_fit, label='linear')\n",
    "# # plt.plot(x_extended, y_extended, label = 'extended linear')\n",
    "# plt.plot(xpoints, quad_fit, label='quadratic')\n",
    "# plt.plot(xpoints, cub_fit, label='cubic')\n",
    "# # plt.scatter(avg_data['Frequency (GHz)'],avg_data['Intensity'], color='m')\n",
    "# plt.scatter(xpoints,ypoints, color='m')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.title(\"Linear Best Fit\")\n",
    "# plt.xlabel(xpoints.name)\n",
    "# plt.ylabel(ypoints.name)\n",
    "\n",
    "for ypoints in ypoints_dict.values():\n",
    "    plt.figure()\n",
    "    lin_fit, lin_param, lin_error = y_model(xmatrix, xpoints, ypoints)\n",
    "    quad_fit, quad_param, quad_error = y_model(xmatrix_quad, xpoints,ypoints)\n",
    "    cub_fit, cub_param, cub_error = y_model(xmatrix_cub,xpoints, ypoints)\n",
    "    \n",
    "    plt.plot(xpoints, lin_fit, label='linear')\n",
    "    plt.plot(xpoints, quad_fit, label='quadratic')\n",
    "    plt.plot(xpoints, cub_fit, label='cubic')\n",
    "    plt.scatter(xpoints,ypoints, color='m')\n",
    "    plt.show()\n",
    "\n",
    "# #plot for second figure\n",
    "# plt.figure(2)\n",
    "# plt.plot(np.log(xpoints), pow_fit, label='power')\n",
    "# plt.scatter(np.log(xpoints),yval_log, color='m')\n",
    "# plt.title(\"Linear Best Fit for Power (log-log)\")\n",
    "# plt.xlabel(xpoints.name)\n",
    "# plt.ylabel(ypoints.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ypoints in ypoints_dict.values():\n",
    "    plt.figure()\n",
    "    yval_log =np.log(ypoints) \n",
    "    pow_fit, pow_param, pow_error = y_model(xmatrix_pow, xval_log, yval_log)\n",
    "    plt.plot(np.log(xpoints), pow_fit, label='power')\n",
    "    plt.scatter(np.log(xpoints),yval_log, color='m')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Errors for Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the error for parameters of the linear fit. The parameters are $b$ for intercept and $m$ for slope from the equation $y=mx+b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error_cov_lin = error_bar(lin_error)\n",
    "print('Error covariance for linear fit is\\n', error_cov_lin)\n",
    "print('\\nThe slope (m) is', lin_param[1],'+/-', error_cov_lin[1], '(',lin_param[1]+error_cov_lin[1],',',\n",
    "      lin_param[1]-error_cov_lin[1],')')\n",
    "print('The intercept (b) is', lin_param[0],'+/-', error_cov_lin[0],'(',lin_param[0]+error_cov_lin[0],',',\n",
    "      lin_param[0]-error_cov_lin[0],')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the error for the parameter of the power law fit. The parameters are $log(\\beta)$ and $\\alpha$ for the equation $y^{'} = log(\\beta) + \\alpha x^{'}$. Note that $y^{'}=log(y)$ and $x^{'}=log(x)$ and that it's for a log-log graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Error covariance for power law fit is \\n', error_cov(xmatrix_pow))\n",
    "# print('\\nLog(beta) is', pow_param[1],'+/-', error_bar(xmatrix_pow)[1], '(',pow_param[1]+error_bar(xmatrix_pow)[1],',',\n",
    "#       pow_param[1]-error_bar(xmatrix_pow)[1],')')\n",
    "# print('Alpha is', pow_param[0],'+/-', error_bar(xmatrix_pow)[0],'(',pow_param[0]+error_bar(xmatrix_pow)[0],',',\n",
    "#       pow_param[0]-error_bar(xmatrix_pow)[0],')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating sigma using a different method and finding the corresponding error for the power law parameters. Here, it seems that the error has been substantially reduced. The error for log is $$\\delta y^{'}= \\frac{d log(y)}{dy} = \\frac{\\delta y}{y}$$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigma = (1/(np.sqrt(np.abs(yval_log)))).reshape((ypoints.size,1))\n",
    "# sigma= np.hstack(sigma)\n",
    "# noise_cov = np.diag(sigma)\n",
    "# err_pow = error_cov(xmatrix_pow)\n",
    "# print(err_pow)\n",
    "# print('\\nLog(beta) is', pow_param[1],'+/-', error_bar(xmatrix_pow)[1], '(',pow_param[1]+error_bar(xmatrix_pow)[1],',',\n",
    "#       pow_param[1]-error_bar(xmatrix_pow)[1],')')\n",
    "# print('Alpha is', pow_param[0],'+/-', error_bar(xmatrix_pow)[0],'(',pow_param[0]+error_bar(xmatrix_pow)[0],',',\n",
    "#       pow_param[0]-error_bar(xmatrix_pow)[0],')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goodness of Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\chi^{2}=\\sum_{i=1} \\frac{(y_{i}-\\hat{m}_{i}-\\hat{b})^{2}}{\\sigma_{i}^{2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = np.sum(((ypoints - avg_x)**2)/(xpoints.size))\n",
    "residual_sq = (ypoints-lin_fit)**2\n",
    "chi_square = np.sum(residual_sq/(var))\n",
    "print(chi_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = np.sum(((ypoints - avg_x)**2)/(xpoints.size))\n",
    "residual_sq = (ypoints-lin_fit)**2\n",
    "chi_square = np.sum(residual_sq/(var))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
